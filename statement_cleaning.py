# -*- coding: utf-8 -*-
"""statement cleaning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1X_aOXgCxRBIFXn__0fQoWnSLYlWQT2rs
"""

import pandas as pd

# Load the dataset (update the file path as necessary)
df = pd.read_csv('/content/bankstatements.csv')
# Display the first few rows to understand the data structure
df.head()

df.describe()
df.columns
print(df.isnull().any().sum())
missing_columns = df.columns[df.isnull().any()]
print("Columns with missing values:", missing_columns)

# Check for duplicate rows
print("Duplicate Rows:", df_new_loaded.duplicated().sum())
# Remove duplicate rows
df_new_no_duplicates = df_new_loaded.drop_duplicates()

# Display the cleaned dataset without duplicates
print(df_new_no_duplicates.head())
# Check how many duplicates are left
print("Remaining duplicate rows:", df_new_no_duplicates.duplicated().sum())

# Convert 'Date' column to datetime using .loc to avoid the warning
df_new_no_duplicates.loc[:, 'date'] = pd.to_datetime(df_new_no_duplicates['date'])

# Verify the data types again
print(df_new_no_duplicates.dtypes)

# Save the cleaned dataset to a new CSV file
df_new_no_duplicates.to_csv('/content/df_new_no_duplicates.csv', index=False)

